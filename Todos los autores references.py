

# ------------------------------------------------------
# Streamlit
# Knowledge Bases for Amazon Bedrock and LangChain ðŸ¦œï¸ðŸ”—
# ------------------------------------------------------

import boto3
import logging

from typing import List, Dict
from pydantic import BaseModel
from operator import itemgetter
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_aws import ChatBedrock
from langchain_aws import AmazonKnowledgeBasesRetriever
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

from markdown import markdown
import html

# ------------------------------------------------------
# Log level

logging.getLogger().setLevel(logging.ERROR) # reduce log level

# ------------------------------------------------------
# Amazon Bedrock - settings

bedrock_runtime = boto3.client(
    service_name="bedrock-runtime",
    region_name="us-east-1",
)

model_id = "anthropic.claude-3-haiku-20240307-v1:0"

model_kwargs =  { 
    "max_tokens": 2048,
    "temperature": 0.0,
    "top_k": 250,
    "top_p": 1,
    "stop_sequences": ["\n\nHuman"],
}

# ------------------------------------------------------
# LangChain - RAG chain with chat history

prompt_old = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful assistant, always answer in Spanish"
         "Answer the question based only on the following context:\n {context}"),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{question}"),
    ]
)

SYSTEM_PROMPTALL = (
"""
### Base de conocimientos:  
{context}  

---

# Prompt del Sistema: Chatbot Especializado en Hazlitt, Mises y Hayek  

## **Identidad del Asistente**  
Eres un asistente virtual especializado en proporcionar explicaciones claras y detalladas sobre los principales conceptos y teorÃ­as de **Henry Hazlitt**, **Ludwig von Mises** y **Friedrich A. Hayek**. Tu propÃ³sito es facilitar el aprendizaje autÃ³nomo y la comprensiÃ³n de sus contribuciones a la filosofÃ­a econÃ³mica, con Ã©nfasis en la Escuela Austriaca de EconomÃ­a. Respondes en espaÃ±ol e inglÃ©s, adaptÃ¡ndote a las necesidades del usuario.  

Puedes responder desde la perspectiva de uno o mÃ¡s de estos autores, segÃºn sea relevante para la pregunta, conectando sus ideas cuando corresponda.  

## **PÃºblico Objetivo**  
### **Audiencia Primaria**:  
- **Estudiantes** (de 18 a 45 aÃ±os) de la **Universidad Francisco MarroquÃ­n (UFM)** en Guatemala.  
- Carreras: economÃ­a, derecho, ciencias polÃ­ticas, filosofÃ­a, administraciÃ³n de empresas y otras relacionadas.  
- Principal enfoque en estudiantes de pregrado interesados en la Escuela Austriaca y sus aplicaciones.  

### **Audiencia Secundaria**:  
- Profesores y acadÃ©micos que deseen integrar las ideas de Hazlitt, Mises y Hayek en sus debates sobre polÃ­tica econÃ³mica y filosofÃ­a polÃ­tica.  

### **Audiencia Terciaria**:  
- Economistas, empresarios y entusiastas de la economÃ­a en **LatinoamÃ©rica, EspaÃ±a**, y otras regiones interesados en los mercados libres, la crÃ­tica al socialismo, y las teorÃ­as del orden espontÃ¡neo, el cÃ¡lculo econÃ³mico y el anÃ¡lisis de polÃ­ticas pÃºblicas.  

---

## **MetodologÃ­a para Respuestas**  
Las respuestas deben seguir una estructura lÃ³gica basada en la metodologÃ­a **5W 1H** (quÃ©, quiÃ©n, cuÃ¡ndo, dÃ³nde, por quÃ©, cÃ³mo). Deben integrar las ideas de uno, dos o los tres autores segÃºn la relevancia para la pregunta planteada.  

- **Introduce el tema o concepto de manera clara y directa.**  
- AmplÃ­a con definiciones, ejemplos histÃ³ricos y aplicaciones contemporÃ¡neas, vinculando las perspectivas de Hazlitt, Mises y Hayek donde sea pertinente.  
- Finaliza con reflexiones o conexiones relevantes al tema.  

---

## **Estructura ImplÃ­cita de Respuesta**  
1. **Contexto inicial**: Presentar el tema con Ã©nfasis en su relevancia y las contribuciones de los autores.  
2. **Desarrollo de ideas**: Explorar conceptos clave, ejemplos prÃ¡cticos y aplicaciones modernas desde una o mÃ¡s perspectivas.  
3. **Cierre reflexivo**: Resumir la idea principal y conectar con implicaciones actuales o debates relevantes.  

---

## **Tono y Estilo**  
- **Profesional y acadÃ©mico**, con un enfoque claro y motivador.  
- Lenguaje preciso y accesible, libre de tecnicismos innecesarios.  
- Estructura fluida que facilite el aprendizaje del lector.  

---

## **GestiÃ³n del Contexto**  
### **RetenciÃ³n de InformaciÃ³n Previa**:  
- Conecta con temas previos utilizando frases como:  
  - *"Como mencionamos en nuestra discusiÃ³n anterior sobre..."*  
  - *"Esto se relaciona directamente con el tema anterior de..."*  

### **Coherencia TemÃ¡tica**:  
- MantÃ©n la continuidad entre preguntas relacionadas. Si el usuario cambia de tema, solicita aclaraciones:  
  - *"Â¿Le gustarÃ­a seguir explorando este tema o pasamos al nuevo?"*  

### **Evita Redundancias**:  
- Resume o parafrasea conceptos previamente explicados de forma breve.  

---

## **Idiomas**  
- Responde en el idioma en que se formula la pregunta.  
- Si se mezcla espaÃ±ol e inglÃ©s, responde en el idioma predominante y ofrece traducciones si es Ãºtil.  

---

## **Transparencia y LÃ­mites**  
- Si no puedes proporcionar informaciÃ³n especÃ­fica:  
  - **Respuesta sugerida**:  
    *"No tengo informaciÃ³n suficiente sobre este tema en mis recursos actuales. Por favor, consulta otras referencias especializadas."*  

---

## **CaracterÃ­sticas Principales**  
1. **Respuestas Estructuradas ImplÃ­citamente**:  
   - Responde de manera fluida, organizando las ideas sin necesidad de secciones explÃ­citas.  
2. **PriorizaciÃ³n en Respuestas Largas**:  
   - EnfÃ³cate en conceptos clave y resume detalles secundarios.  
3. **Adaptabilidad a Preguntas Complejas**:  
   - Divide preguntas multifacÃ©ticas en respuestas claras y conectadas.  

---

## **EvaluaciÃ³n de Respuestas**  
Las respuestas deben ser:  
- **Relevantes**: Directamente relacionadas con la pregunta planteada.  
- **Claras**: Presentadas de manera lÃ³gica y accesible.  
- **Precisas**: Fundamentadas en las ideas de Hazlitt, Mises y Hayek segÃºn sea relevante.  
- **Comprensibles**: Usando un lenguaje claro y enriquecedor.  

---

"""
)


def create_prompt_template_all():
    return ChatPromptTemplate.from_messages(
        [
            ("system", SYSTEM_PROMPTALL),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}")
        ]
    )

# Amazon Bedrock - KnowledgeBase Retriever 
retriever = AmazonKnowledgeBasesRetriever(
    knowledge_base_id="WGUUTHDVPH", #  Knowledge base ID
    retrieval_config={"vectorSearchConfiguration": {"numberOfResults": 20}},
)

model = ChatBedrock(
    client=bedrock_runtime,
    model_id=model_id,
    model_kwargs=model_kwargs,
)

prompt_all = create_prompt_template_all()

chain = (
    RunnableParallel({
        "context": itemgetter("question") | retriever,
        "question": itemgetter("question"),
        "history": itemgetter("history"),
    })
    .assign(response = prompt_all | model | StrOutputParser())
    .pick(["response", "context"])
)

# Streamlit Chat Message History
history = StreamlitChatMessageHistory(key="chat_messages")

# Chain with History
chain_with_history = RunnableWithMessageHistory(
    chain,
    lambda session_id: history,
    input_messages_key="question",
    history_messages_key="history",
    output_messages_key="response",
)






# ------------------------------------------------------
# Pydantic data model and helper function for Citations

class Citation(BaseModel):
    page_content: str
    metadata: Dict

def extract_citations(response: List[Dict]) -> List[Citation]:
    return [Citation(page_content=doc.page_content, metadata=doc.metadata) for doc in response]

# ------------------------------------------------------
# S3 Presigned URL, esto permite realizar descargar del documento

def create_presigned_url(bucket_name: str, object_name: str, expiration: int = 300) -> str:
    """Generate a presigned URL to share an S3 object"""
    s3_client = boto3.client('s3')
    try:
        response = s3_client.generate_presigned_url('get_object',
                                                    Params={'Bucket': bucket_name,
                                                            'Key': object_name},
                                                    ExpiresIn=expiration)
    except NoCredentialsError:
        st.error("AWS credentials not available")
        return ""
    return response

def parse_s3_uri(uri: str) -> tuple:
    """Parse S3 URI to extract bucket and key"""
    parts = uri.replace("s3://", "").split("/")
    bucket = parts[0]
    key = "/".join(parts[1:])
    return bucket, key

# ------------------------------------------------------
# Streamlit

import streamlit as st

# Page title
st.set_page_config(page_title='Chatbot CHH')

st.subheader('Todos los autores ðŸ”—', divider='rainbow')


# FunciÃ³n para formatear el historial

def display_history1(history):
    for message in history:
        content = message.content
        #safe_content = html.escape(message.content)  # Escapar HTML
        #html_content = markdown(message.content)  
        if message.__class__.__name__ == 'HumanMessage':  # Mensajes del usuario
            st.markdown(
                f"""
                <div style="padding: 10px; margin-bottom: 10px; background-color: #0e1117; border-radius: 8px; color: #F3F4F6; font-size: 0.9em;">
                    <strong>Usuario:</strong><br>
                    {content}
                </div>
                """, unsafe_allow_html=True)
        elif message.__class__.__name__ == 'AIMessage':  # Respuestas del chatbot
            st.markdown(
                f"""
                <div style="padding: 10px; margin-bottom: 10px; background-color: #0e1117; border-left: 5px solid #FF9F1C; border-radius: 8px; color: #E5E7EB; font-size: 0.9em;">
                    <strong>Chatbot (Todos los autores):</strong><br>
                    {content}
                </div>
                """, unsafe_allow_html=True)
            

## Ejemplo de lo que esta en history.messages
history_placeholders = [
    type('HumanMessage', (object,), {"content": "Â¿CuÃ¡les son las similitudes clave entre Hayek y Mises?"})(),
    type('AIMessage', (object,), {"content": "Ambos fueron defensores del libre mercado y crÃ­ticos del intervencionismo estatal..."})()
]


def show_modal(citations):
    st.markdown(
        """
        <style>
        .modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.8);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 1000;
        }
        .modal-content {
            background-color: #1e293b;
            padding: 20px;
            border-radius: 8px;
            max-width: 600px;
            width: 90%;
            color: #f3f4f6;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            overflow-y: auto;
            max-height: 80%;
        }
        .close-btn {
            color: white;
            float: right;
            font-size: 20px;
            font-weight: bold;
            cursor: pointer;
        }
        </style>
        """, unsafe_allow_html=True
    )
    st.markdown(
        f"""
        <div class="modal">
            <div class="modal-content">
                <span class="close-btn" onclick="document.querySelector('.modal').style.display='none'">&times;</span>
                <h3>Referencias relacionadas</h3>
                <ul>
                    {"".join([f"<li>{citation['page_content']}</li>" for citation in citations])}
                </ul>
            </div>
        </div>
        """, unsafe_allow_html=True
    ) 

# Clear Chat History function
def clear_chat_history():
    history.clear()
    st.session_state.messages = [{"role": "assistant", "content": "PregÃºntame sobre economÃ­a"}]

with st.sidebar:
    st.title('Todos los autores ðŸ”—')

    streaming_on = True

    with st.expander("Ver historial de conversaciÃ³n", expanded=False):  # collapsed por defecto
        display_history1(history.messages) 

    st.divider()

   

# Initialize session state for messages if not already present
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "PregÃºntame sobre economÃ­a"}]

# Display chat messages

#for message in st.session_state.messages:
#    with st.chat_message(message["role"]):
#        st.write(message["content"])


# Mostrar historial de chat con referencias
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])
        
        # Mostrar referencias si existen
        if "citations" in message and message["citations"]:
            with st.expander("Mostrar referencias >"):
                for citation in message["citations"]:
                    st.write(f"**Contenido:** {citation.page_content}")
                    s3_uri = citation.metadata['location']['s3Location']['uri']
                    bucket, key = parse_s3_uri(s3_uri)
                    st.write(f"**Fuente:** *{key}*")
                    st.write("--------------")

# Chat Input - User Prompt 
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    config = {"configurable": {"session_id": "any"}}
    
    if streaming_on:
        # Chain - Stream
        with st.chat_message("assistant"):
            placeholder = st.empty()
            full_response = ''
            for chunk in chain_with_history.stream(
                {"question" : prompt, "history" : history},
                config
            ):
                if 'response' in chunk:
                    full_response += chunk['response']
                    placeholder.markdown(full_response)
                else:
                    full_context = chunk['context']
            placeholder.markdown(full_response)
            # Citations with S3 pre-signed URL
            citations = extract_citations(full_context)
            with st.expander("Mostrar referencias >"):
                for citation in citations:
                    st.write("**Contenido:** ", citation.page_content)
                    s3_uri = citation.metadata['location']['s3Location']['uri']
                    bucket, key = parse_s3_uri(s3_uri)

                      #  presigned_url = create_presigned_url(bucket, key)
                     #   if presigned_url:
                     #       st.markdown(f"**Fuente:** [{s3_uri}]({presigned_url})")
                     #   else:
                      #  st.write(f"**Fuente**: {s3_uri} (Presigned URL generation failed)")
                    st.write(f"**Fuente**: *{key}* ")
                    st.write("--------------")

            # session_state append
            #st.session_state.messages.append({"role": "assistant", "content": full_response})


            #session_state con referencias
            st.session_state.messages.append({
            "role": "assistant",
            "content": full_response,
            "citations": citations  # Guardar referencias junto con la respuesta.
        })
            
        #print(st.session_state)

  

